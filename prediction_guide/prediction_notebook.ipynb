{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def audio_to_audio_frame_stack(sound_data, frame_length, hop_length_frame):\n",
    "    \"\"\"This function take an audio and split into several frame\n",
    "       in a numpy matrix of size (nb_frame,frame_length)\"\"\"\n",
    "\n",
    "    sequence_sample_length = sound_data.shape[0]\n",
    "\n",
    "    sound_data_list = [sound_data[start:start + frame_length] for start in range(\n",
    "    0, sequence_sample_length - frame_length + 1, hop_length_frame)]  # get sliding windows\n",
    "    sound_data_array = np.vstack(sound_data_list)\n",
    "\n",
    "    return sound_data_array\n",
    "\n",
    "\n",
    "def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame, min_duration):\n",
    "    \"\"\"This function take audio files of a directory and merge them\n",
    "    in a numpy matrix of size (nb_frame,frame_length) for a sliding window of size hop_length_frame\"\"\"\n",
    "\n",
    "    list_sound_array = []\n",
    "\n",
    "    for file in list_audio_files:\n",
    "        # open the audio file\n",
    "        y, sr = librosa.load(os.path.join(audio_dir, file), sr=sample_rate)\n",
    "        total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        if (total_duration >= min_duration):\n",
    "            list_sound_array.append(audio_to_audio_frame_stack(\n",
    "                y, frame_length, hop_length_frame))\n",
    "        else:\n",
    "            print(\n",
    "                f\"The following file {os.path.join(audio_dir,file)} is below the min duration\")\n",
    "\n",
    "    return np.vstack(list_sound_array)\n",
    "\n",
    "\n",
    "def audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, audio):\n",
    "    \"\"\"This function takes an audio and convert into spectrogram,\n",
    "       it returns the magnitude in dB and the phase\"\"\"\n",
    "\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(\n",
    "        stftaudio_magnitude, ref=np.max)\n",
    "\n",
    "    return stftaudio_magnitude_db, stftaudio_phase\n",
    "\n",
    "\n",
    "def numpy_audio_to_matrix_spectrogram(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n",
    "    \"\"\"This function takes as input a numpy audi of size (nb_frame,frame_length), and return\n",
    "    a numpy containing the matrix spectrogram for amplitude in dB and phase. It will have the size\n",
    "    (nb_frame,dim_square_spec,dim_square_spec)\"\"\"\n",
    "\n",
    "    nb_audio = numpy_audio.shape[0]\n",
    "\n",
    "    m_mag_db = np.zeros((nb_audio, dim_square_spec, dim_square_spec))\n",
    "    m_phase = np.zeros((nb_audio, dim_square_spec, dim_square_spec), dtype=complex)\n",
    "\n",
    "    for i in range(nb_audio):\n",
    "        m_mag_db[i, :, :], m_phase[i, :, :] = audio_to_magnitude_db_and_phase(\n",
    "            n_fft, hop_length_fft, numpy_audio[i])\n",
    "\n",
    "    return m_mag_db, m_phase\n",
    "\n",
    "\n",
    "def magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, stftaudio_magnitude_db, stftaudio_phase):\n",
    "    \"\"\"This functions reverts a spectrogram to an audio\"\"\"\n",
    "\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # taking magnitude and phase of audio\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "    audio_reconstruct = librosa.core.istft(audio_reverse_stft, hop_length=hop_length_fft, length=frame_length)\n",
    "\n",
    "    return audio_reconstruct\n",
    "\n",
    "def matrix_spectrogram_to_numpy_audio(m_mag_db, m_phase, frame_length, hop_length_fft)  :\n",
    "    \"\"\"This functions reverts the matrix spectrograms to numpy audio\"\"\"\n",
    "\n",
    "    list_audio = []\n",
    "\n",
    "    nb_spec = m_mag_db.shape[0]\n",
    "\n",
    "    for i in range(nb_spec):\n",
    "\n",
    "        audio_reconstruct = magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, m_mag_db[i], m_phase[i])\n",
    "        list_audio.append(audio_reconstruct)\n",
    "\n",
    "    return np.vstack(list_audio)\n",
    "\n",
    "def scaled_in(matrix_spec):\n",
    "    \"global scaling apply to noisy voice spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec + 46)/50\n",
    "    return matrix_spec\n",
    "\n",
    "def inv_scaled_ou(matrix_spec):\n",
    "    \"inverse global scaling apply to noise models spectrograms\"\n",
    "    matrix_spec = matrix_spec * 82 + 6\n",
    "    return matrix_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction, audio_input_prediction,\n",
    "audio_output_prediction, sample_rate, min_duration, frame_length, hop_length_frame, n_fft, hop_length_fft):\n",
    "    \"\"\" This function takes as input pretrained weights, noisy voice sound to denoise, predict\n",
    "    the denoise sound and save it to disk.\n",
    "    \"\"\"\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model = load_model(weights_path+'/'+name_model+'.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    # Extracting noise and voice from folder and convert to numpy\n",
    "    audio = audio_files_to_numpy(audio_dir_prediction, audio_input_prediction, sample_rate,\n",
    "                                 frame_length, hop_length_frame, min_duration)\n",
    "\n",
    "    #Dimensions of squared spectrogram\n",
    "    dim_square_spec = int(n_fft / 2) + 1\n",
    "    print(dim_square_spec)\n",
    "\n",
    "    # Create Amplitude and phase of the sounds\n",
    "    m_amp_db_audio,  m_pha_audio = numpy_audio_to_matrix_spectrogram(\n",
    "        audio, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "    #global scaling to have distribution -1/1\n",
    "    X_in = scaled_in(m_amp_db_audio)\n",
    "    #Reshape for prediction\n",
    "    X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n",
    "    #Prediction using loaded network\n",
    "    X_pred = loaded_model.predict(X_in)\n",
    "    #Rescale back the noise model\n",
    "    inv_sca_X_pred = inv_scaled_ou(X_pred)\n",
    "    #Remove noise model from noisy speech\n",
    "    X_denoise = m_amp_db_audio - inv_sca_X_pred[:,:,:,0]\n",
    "    #Reconstruct audio from denoised spectrogram and phase\n",
    "    print(X_denoise.shape)\n",
    "    print(m_pha_audio.shape)\n",
    "    print(frame_length)\n",
    "    print(hop_length_fft)\n",
    "    audio_denoise_recons = matrix_spectrogram_to_numpy_audio(X_denoise, m_pha_audio, frame_length, hop_length_fft)\n",
    "    #Number of frames\n",
    "    nb_samples = audio_denoise_recons.shape[0]\n",
    "    #Save all frames in one file\n",
    "    denoise_long = audio_denoise_recons.reshape(1, nb_samples * frame_length)*10\n",
    "    librosa.output.write_wav(dir_save_prediction + audio_output_prediction, denoise_long[0, :], sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/content/Train/model/'                    #folder of saved weights\n",
    "name_model = 'model_unet'                                 #Name of saved model to read\n",
    "audio_dir_prediction = '/content/Test/noisy_voice'        #directory where prediction() function read noisy sound for denoise\n",
    "dir_save_prediction = '/content/Test/save_predictions/'   #directory to save the denoise sound\n",
    "audio_input_prediction = ['noisy_voice_long_t2.wav']      #Noisy sound file to denoise\n",
    "audio_output_prediction = 'denoise_t2.wav'                #File name of sound output of denoise prediction\n",
    "sample_rate = 8000                                        #Sample rate chosen to read audio\n",
    "min_duration = 1.0                                        #Minimum duration of audio files to consider\n",
    "frame_length = 8064                                       #Training data will be frame of slightly above 1 second\n",
    "hop_length_frame = 8064                                   #hop length for clean voice files separation (no overlap\n",
    "hop_length_frame_noise = 5000                             #hop length for noise files to blend (noise is splitted into several windows)\n",
    "n_fft = 255                                               #Choosing n_fft to have squared spectrograms\n",
    "hop_length_fft = 63                                       #Choosing hop_length_fft to have squared spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction, audio_input_prediction, audio_output_prediction, sample_rate, min_duration, frame_length, hop_length_frame, n_fft, hop_length_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
